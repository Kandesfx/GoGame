# ğŸš€ Tá»‘i Æ¯u Cho Colab 50GB RAM - Single Worker

## âœ… Cáº¥u HÃ¬nh

- **Workers**: 1 (single-threaded)
- **RAM**: 50GB (táº­n dá»¥ng vá»›i chunk size lá»›n)
- **Multiprocessing**: Disabled (default)

## ğŸ¯ Tá»‘i Æ¯u

### 1. **Chunk Size Lá»›n** (Táº­n Dá»¥ng 50GB RAM)
- âœ… Default: 100K samples (~5GB)
- âœ… Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh lÃªn Ä‘áº¿n 300K samples (~15GB)
- âœ… Giáº£m I/O overhead, táº­n dá»¥ng RAM

### 2. **Single-Threaded Optimized**
- âœ… Reuse label generators (giáº£m overhead)
- âœ… Tá»‘c Ä‘á»™: ~100-150 pos/s
- âœ… á»”n Ä‘á»‹nh, khÃ´ng bá»‹ Ä‘á»©ng

### 3. **Memory Management**
- âœ… Chunk size lá»›n = Ã­t I/O hÆ¡n
- âœ… GC Ã­t thÆ°á»ng xuyÃªn hÆ¡n (má»—i 20K)
- âœ… Táº­n dá»¥ng RAM Ä‘á»ƒ cache nhiá»u data

## ğŸ“‹ CÃ¡ch Sá»­ Dá»¥ng

### Basic (Recommended)

```python
from pathlib import Path
from generate_labels_colab import process_dataset_file

WORK_DIR = Path('/content/drive/MyDrive/GoGame_ML')

# Single-threaded vá»›i 1 worker, táº­n dá»¥ng 50GB RAM
process_dataset_file(
    input_path=WORK_DIR / 'processed' / 'positions_19x19_2019.pt',
    output_path=WORK_DIR / 'datasets' / 'labeled_19x19_2019.pt',
    filter_handicap=True
    # num_workers=1 (default)
    # use_multiprocessing=False (default)
    # save_chunk_size tá»± Ä‘á»™ng = 100K-300K
)
```

### Manual Tuning

```python
# Tá»‘i Æ°u tá»‘i Ä‘a vá»›i chunk size lá»›n
process_dataset_file(
    input_path=...,
    output_path=...,
    save_chunk_size=200000,  # 200K samples (~10GB)
    num_workers=1,  # Single-threaded
    use_multiprocessing=False
)
```

## ğŸ“Š Performance

### Single-Threaded (1 Worker):
- **Speed**: ~100-150 pos/s
- **Memory**: 5-15GB (tÃ¹y chunk size)
- **Stability**: âœ… Ráº¥t á»•n Ä‘á»‹nh
- **Dataset**: KhÃ´ng giá»›i háº¡n (vá»›i incremental save)

## âš™ï¸ Tuning Chunk Size

### Dataset Nhá» (<200K positions):
```python
save_chunk_size=300000  # 300K samples (~15GB) - táº­n dá»¥ng RAM tá»‘i Ä‘a
```

### Dataset Trung BÃ¬nh (200K-500K positions):
```python
save_chunk_size=200000  # 200K samples (~10GB)
```

### Dataset Lá»›n (>500K positions):
```python
save_chunk_size=100000  # 100K samples (~5GB)
```

## ğŸ“ˆ Expected Performance

Vá»›i dataset 624K positions trÃªn 50GB RAM (1 worker):
- **Thá»i gian**: ~1.5-2 giá» (100-150 pos/s)
- **Memory**: 5-15GB (tÃ¹y chunk size)
- **Stability**: âœ… Ráº¥t á»•n Ä‘á»‹nh, khÃ´ng bá»‹ Ä‘á»©ng

## ğŸ¯ Best Practices

1. **Chunk Size**: DÃ¹ng lá»›n (100K-300K) Ä‘á»ƒ táº­n dá»¥ng RAM
2. **Single-Threaded**: 1 worker = á»•n Ä‘á»‹nh, khÃ´ng bá»‹ Ä‘á»©ng
3. **Monitor**: Váº«n nÃªn monitor memory (dÃ¹ cÃ³ 50GB)
4. **I/O**: Chunk size lá»›n = Ã­t I/O hÆ¡n = nhanh hÆ¡n

## âš ï¸ LÆ°u Ã

1. **Chunk Size**: KhÃ´ng nÃªn quÃ¡ 300K (trÃ¡nh overhead khi save)
2. **Memory**: DÃ¹ cÃ³ 50GB, váº«n nÃªn dÃ¹ng incremental save
3. **Speed**: Single-threaded cháº­m hÆ¡n multiprocessing nhÆ°ng á»•n Ä‘á»‹nh hÆ¡n

## ğŸ”— LiÃªn Quan

- `scripts/generate_labels_colab.py` - Script Ä‘Ã£ tá»‘i Æ°u
- `scripts/SINGLE_THREADED_OPTIMIZATION.md` - Chi tiáº¿t tá»‘i Æ°u single-threaded
- `scripts/COLAB_50GB_RAM_OPTIMIZATION.md` - Náº¿u muá»‘n enable multiprocessing

