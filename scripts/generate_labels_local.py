"""
Script t·ªëi ∆∞u ƒë·ªÉ generate labels tr√™n local m√°y t√≠nh.

T√≠nh nƒÉng:
- Multiprocessing ƒë·ªÉ tƒÉng t·ªëc
- Error handling v√† logging
- X·ª≠ l√Ω theo batch ƒë·ªÉ ti·∫øt ki·ªám memory
- Progress tracking
"""

import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
import logging
from datetime import datetime
import traceback
from multiprocessing import Pool, cpu_count
import sys
import signal
import time
import gc

# Import features
try:
    from generate_features_colab import (
        board_to_features_17_planes,
        generate_policy_label,
        generate_value_label
    )
except ImportError:
    # N·∫øu ch∆∞a c√≥, th·ª≠ import t·ª´ th∆∞ m·ª•c hi·ªán t·∫°i
    sys.path.insert(0, str(Path(__file__).parent))
    from generate_features_colab import (
        board_to_features_17_planes,
        generate_policy_label,
        generate_value_label
    )

# Setup logging with UTF-8 encoding
import sys

# Create file handler with UTF-8
file_handler = logging.FileHandler('generate_labels_local.log', encoding='utf-8')
file_handler.setLevel(logging.INFO)

# Create console handler with UTF-8 (if possible)
try:
    console_handler = logging.StreamHandler(sys.stdout)
    # Try to set UTF-8 encoding for console
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
except:
    console_handler = logging.StreamHandler()

console_handler.setLevel(logging.INFO)

# Create formatter
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
console_handler.setFormatter(formatter)

# Setup logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(file_handler)
logger.addHandler(console_handler)


def process_single_position(pos, board_size):
    """
    Process m·ªôt position th√†nh labeled sample.
    
    Returns:
        (labeled_sample, error_info) tuple
    """
    try:
        board_state = pos['board_state']
        current_player = pos['current_player']
        move = pos['move']
        winner = pos.get('winner')
        game_result = pos.get('game_result')
        move_number = pos.get('move_number', 0)
        
        # Convert numpy board to tensor
        if isinstance(board_state, np.ndarray):
            board_np = board_state
        else:
            board_np = np.array(board_state)
        
        # Validate board size
        if board_np.shape[0] != board_size or board_np.shape[1] != board_size:
            return None, {
                'error': f'Board size mismatch: {board_np.shape} vs {board_size}',
                'type': 'size_mismatch'
            }
        
        # Get move history (simplified - t·ª´ move_number)
        move_history = []  # Will be handled in batch processing
        
        # Generate 17-plane features
        features = board_to_features_17_planes(
            board_np,
            current_player,
            move_history=move_history,
            board_size=board_size
        )
        
        # Generate policy label
        policy = generate_policy_label(move, board_size)
        
        # Generate value label
        value = generate_value_label(winner, current_player, game_result)
        
        # Create labeled sample
        labeled_sample = {
            'features': features,
            'policy': policy,
            'value': value,
            'metadata': {
                'move_number': move_number,
                'game_result': game_result,
                'winner': winner,
                'handicap': pos.get('handicap', 0)
            }
        }
        
        return labeled_sample, None
        
    except Exception as e:
        error_info = {
            'error': str(e),
            'type': 'exception',
            'traceback': traceback.format_exc(),
            'position': {
                'move_number': pos.get('move_number', -1),
                'current_player': pos.get('current_player', '?')
            }
        }
        return None, error_info


def process_positions_batch(positions_batch, board_size):
    """
    Process m·ªôt batch positions v·ªõi move history tracking.
    
    Args:
        positions_batch: List of positions t·ª´ c√πng m·ªôt game
        board_size: Board size
    
    Returns:
        (labeled_samples, errors) tuple
    """
    labeled_samples = []
    errors = []
    move_history = []
    
    for pos in positions_batch:
        # Update move history
        if pos.get('move_number', 0) == 0:
            move_history = []
        
        # Process position
        labeled_sample, error_info = process_single_position(pos, board_size)
        
        if error_info is not None:
            errors.append(error_info)
            continue
        
        if labeled_sample is None:
            continue
        
        # Update features v·ªõi move history (n·∫øu c·∫ßn)
        # Note: Move history ƒë√£ ƒë∆∞·ª£c t√≠nh trong batch processing
        labeled_samples.append(labeled_sample)
        
        # Update move history
        move = pos.get('move')
        if move:
            move_history.append(move)
            if len(move_history) > 4:
                move_history = move_history[-4:]
    
    return labeled_samples, errors


def _process_batch_wrapper(args):
    """Wrapper function for multiprocessing (kh√¥ng th·ªÉ d√πng lambda)."""
    batch, board_size = args
    return process_positions_batch(batch, board_size)


def process_positions_to_labels_parallel(
    positions,
    board_size,
    num_workers=None,
    batch_size=5000,  # Batch size m·∫∑c ƒë·ªãnh (t·ªëi ∆∞u cho performance)
    save_chunk_size=None,  # N·∫øu set, s·∫Ω save ƒë·ªãnh k·ª≥ thay v√¨ gi·ªØ t·∫•t c·∫£ trong memory
    output_dir=None  # Directory ƒë·ªÉ save chunks n·∫øu d√πng incremental save
):
    """
    Process positions v·ªõi multiprocessing (t·ªëi ∆∞u).
    
    Args:
        positions: List of position dicts
        board_size: Board size
        num_workers: Number of worker processes
        batch_size: Batch size for processing (gi·∫£m ƒë·ªÉ gi·∫£m memory)
        save_chunk_size: N·∫øu set, save ƒë·ªãnh k·ª≥ m·ªói N samples ƒë·ªÉ gi·∫£m memory
    
    Returns:
        (labeled_data, errors) tuple
    """
    if num_workers is None:
        num_workers = min(cpu_count(), 8)
    
    # Memory warning n·∫øu qu√° nhi·ªÅu workers
    if num_workers > 12:
        logger.warning(
            f"‚ö†Ô∏è  WARNING: {num_workers} workers c√≥ th·ªÉ g√¢y RAM overflow. "
            f"Khuy·∫øn ngh·ªã: gi·∫£m xu·ªëng 8 ho·∫∑c √≠t h∆°n."
        )
    
    logger.info(
        f"Processing {len(positions):,} positions with {num_workers} workers "
        f"(batch size: {batch_size:,})"
    )
    
    # Group positions by game (simplified - d·ª±a v√†o move_number)
    batches = []
    current_batch = []
    last_move_num = -1
    
    for pos in positions:
        move_num = pos.get('move_number', 0)
        
        # Start new batch if move_number resets
        if move_num < last_move_num:
            if current_batch:
                batches.append(current_batch)
            current_batch = [pos]
        else:
            current_batch.append(pos)
        
        # Flush batch if too large
        if len(current_batch) >= batch_size:
            batches.append(current_batch)
            current_batch = []
        
        last_move_num = move_num
    
    if current_batch:
        batches.append(current_batch)
    
    logger.info(f"Created {len(batches):,} batches")
    
    # Initialize lists
    total_positions = len(positions)
    all_labeled_data = []
    all_errors = []
    
    processed_positions = 0
    total_errors = 0
    last_log_progress = 0
    
    # Tracking th·ªùi gian ƒë·ªÉ t√≠nh t·ªëc ƒë·ªô th·ª±c t·∫ø
    start_time = time.time()
    last_speed_check_time = start_time
    last_speed_check_positions = 0
    
    # Memory management: n·∫øu save_chunk_size ƒë∆∞·ª£c set, s·∫Ω save ƒë·ªãnh k·ª≥
    # v√† clear memory ƒë·ªÉ tr√°nh RAM overflow
    use_incremental_save = save_chunk_size is not None and save_chunk_size > 0
    saved_chunks = []  # List ƒë·ªÉ l∆∞u path c·ªßa c√°c chunk files n·∫øu d√πng incremental save
    chunk_counter = 0
    
    # T·∫°o chunks directory n·∫øu c·∫ßn
    if use_incremental_save and output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"üìÅ Chunks will be saved to: {output_dir}")
    
    # Process in parallel v·ªõi imap_unordered (nhanh h∆°n v√¨ kh√¥ng c·∫ßn gi·ªØ th·ª© t·ª±)
    # D√πng pool th·ªß c√¥ng thay v√¨ context manager ƒë·ªÉ c√≥ th·ªÉ terminate khi interrupt
    pool = None
    try:
        pool = Pool(processes=num_workers)
        # Progress bar v·ªõi th√¥ng tin chi ti·∫øt
        with tqdm(
            total=total_positions,
            desc="Generating labels",
            unit="pos",
            unit_scale=True,
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] | Errors: {postfix}",
            miniters=1000,  # Update √≠t h∆°n ƒë·ªÉ gi·∫£m overhead
            smoothing=0.05  # Smoothing nh·∫π h∆°n ƒë·ªÉ ph·∫£n √°nh t·ªëc ƒë·ªô th·ª±c t·∫ø
        ) as pbar:
            # D√πng imap_unordered ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô (kh√¥ng c·∫ßn gi·ªØ th·ª© t·ª± batches)
            for labeled_samples, errors in pool.imap_unordered(
                _process_batch_wrapper,
                [(batch, board_size) for batch in batches],
                chunksize=max(1, len(batches) // (num_workers * 4))  # Chunk size t·ªëi ∆∞u
            ):
                # Update progress
                batch_size_processed = len(labeled_samples) + len(errors)
                processed_positions += batch_size_processed
                total_errors += len(errors)
                
                # T√≠nh t·ªëc ƒë·ªô th·ª±c t·∫ø (kh√¥ng ph·ª• thu·ªôc v√†o tqdm smoothing)
                current_time = time.time()
                time_since_last_check = current_time - last_speed_check_time
                
                # Log t·ªëc ƒë·ªô th·ª±c t·∫ø m·ªói 15 gi√¢y ƒë·ªÉ ph√°t hi·ªán slowdown
                if time_since_last_check >= 15.0:
                    positions_since_last_check = processed_positions - last_speed_check_positions
                    real_time_speed = positions_since_last_check / time_since_last_check if time_since_last_check > 0 else 0
                    total_elapsed = current_time - start_time
                    avg_speed = processed_positions / total_elapsed if total_elapsed > 0 else 0
                    
                    # Estimate memory usage
                    # M·ªói labeled sample: features (17 planes x 19x19 x float32) + policy + value
                    # ~17 * 19 * 19 * 4 bytes + 361 * 4 bytes + 4 bytes ‚âà 25KB per sample
                    estimated_memory_mb = len(all_labeled_data) * 25 / 1024
                    
                    # Log v√†o file ƒë·ªÉ ph√¢n t√≠ch
                    logger.info(
                        f"Speed check - Real-time: {real_time_speed:.0f} pos/s | "
                        f"Average: {avg_speed:.0f} pos/s | "
                        f"Samples in memory: {len(all_labeled_data):,} (~{estimated_memory_mb:.0f}MB) | "
                        f"Progress: {processed_positions:,}/{total_positions:,} ({processed_positions/total_positions*100:.1f}%)"
                    )
                    
                    # Memory warning n·∫øu qu√° cao
                    if estimated_memory_mb > 3000:  # > 3GB
                        logger.warning(
                            f"‚ö†Ô∏è  High memory usage: ~{estimated_memory_mb:.0f}MB. "
                            f"Consider reducing batch_size or num_workers."
                        )
                    
                    last_speed_check_time = current_time
                    last_speed_check_positions = processed_positions
                
                # Collect results (d√πng extend thay v√¨ append t·ª´ng item)
                if labeled_samples:
                    all_labeled_data.extend(labeled_samples)
                if errors:
                    all_errors.extend(errors)
                
                # Memory management: Save ƒë·ªãnh k·ª≥ n·∫øu c·∫ßn ƒë·ªÉ tr√°nh MemoryError
                if use_incremental_save and output_dir is not None and len(all_labeled_data) >= save_chunk_size:
                    chunk_counter += 1
                    chunk_file = Path(output_dir) / f'chunk_{chunk_counter:04d}.pt'
                    
                    logger.info(f"üíæ Saving chunk {chunk_counter} ({len(all_labeled_data):,} samples) to {chunk_file.name}")
                    
                    # Save chunk
                    torch.save({
                        'labeled_data': all_labeled_data,
                        'board_size': board_size,
                        'chunk_num': chunk_counter
                    }, chunk_file)
                    
                    saved_chunks.append(chunk_file)
                    
                    # Clear memory v√† force GC
                    all_labeled_data = []
                    gc.collect()
                    
                    logger.info(f"‚úÖ Chunk {chunk_counter} saved. Memory cleared.")
                
                # Periodic GC m·ªói 20K samples (ngay c·∫£ khi kh√¥ng d√πng incremental save)
                elif len(all_labeled_data) % 20000 == 0 and len(all_labeled_data) > 0:
                    gc.collect()
                
                # Update progress bar (√≠t th∆∞·ªùng xuy√™n h∆°n)
                pbar.update(batch_size_processed)
                pbar.set_postfix_str(f"{total_errors:,}")
                
                # Log progress every 10% (kh√¥ng l√†m h·ªèng progress bar)
                progress_pct = (processed_positions / total_positions) * 100
                if progress_pct - last_log_progress >= 10.0:
                    success_rate = ((processed_positions - total_errors) / processed_positions * 100) if processed_positions > 0 else 0
                    elapsed = current_time - start_time
                    avg_speed = processed_positions / elapsed if elapsed > 0 else 0
                    tqdm.write(
                        f"Progress: {progress_pct:.1f}% | "
                        f"Processed: {processed_positions:,}/{total_positions:,} | "
                        f"Success: {success_rate:.1f}% | "
                        f"Errors: {total_errors:,} | "
                        f"Avg Speed: {avg_speed:.0f} pos/s"
                    )
                    last_log_progress = progress_pct
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  Interrupted by user (Ctrl+C). Cleaning up worker processes...")
        if pool is not None:
            logger.info("Terminating worker processes...")
            pool.terminate()  # Force terminate all workers immediately
            # Python 3.12 kh√¥ng h·ªó tr·ª£ timeout trong pool.join()
            # D√πng c√°ch kh√°c ƒë·ªÉ timeout
            import threading
            def join_with_timeout():
                pool.join()
            join_thread = threading.Thread(target=join_with_timeout)
            join_thread.daemon = True
            join_thread.start()
            join_thread.join(timeout=5)  # Wait up to 5 seconds
            if join_thread.is_alive():
                logger.warning("Some worker processes may still be running")
            else:
                logger.info("Worker processes terminated.")
        raise  # Re-raise ƒë·ªÉ main c√≥ th·ªÉ handle
    finally:
        # ƒê·∫£m b·∫£o cleanup pool
        if pool is not None:
            pool.close()  # Prevent new tasks
            # Python 3.12 kh√¥ng h·ªó tr·ª£ timeout trong pool.join()
            pool.join()  # Wait for cleanup (kh√¥ng c√≥ timeout)
    
    # N·∫øu d√πng incremental save, return saved_chunks thay v√¨ all_labeled_data
    if use_incremental_save:
        return saved_chunks, all_errors
    else:
        return all_labeled_data, all_errors


def process_dataset_file(
    input_path,
    output_path,
    filter_handicap=True,
    num_workers=None,
    batch_size=5000  # Batch size m·∫∑c ƒë·ªãnh (t·ªëi ∆∞u cho performance)
):
    """
    Process m·ªôt file positions v√† generate labels.
    
    Args:
        input_path: Path to positions file (.pt)
        output_path: Path to save labeled dataset (.pt)
        filter_handicap: N·∫øu True, b·ªè qua positions c√≥ handicap
        num_workers: Number of worker processes
        batch_size: Batch size for processing
    """
    logger.info(f"Loading positions from: {input_path}")
    
    try:
        # PyTorch 2.6+ requires weights_only=False for files with numpy arrays
        data = torch.load(input_path, map_location='cpu', weights_only=False)
    except Exception as e:
        logger.error(f"Failed to load {input_path}: {e}")
        return None
    
    positions = data['positions']
    board_size = data['board_size']
    year = data.get('year')
    
    logger.info(f"   Board size: {board_size}x{board_size}")
    logger.info(f"   Total positions: {len(positions):,}")
    if year:
        logger.info(f"   Year: {year}")
    
    # Memory warning n·∫øu qu√° nhi·ªÅu positions
    # Estimate: m·ªói position ~1-2KB raw, sau khi label ~50KB
    estimated_memory_mb = len(positions) * 50 / 1024  # Rough estimate
    if estimated_memory_mb > 2000:  # > 2GB
        logger.warning(
            f"‚ö†Ô∏è  WARNING: Estimated memory usage: ~{estimated_memory_mb:.0f}MB. "
            f"Consider reducing num_workers or batch_size to avoid RAM issues."
        )
        if num_workers is None or num_workers > 8:
            suggested_workers = min(8, cpu_count())
            logger.info(f"üí° Suggested: Use --workers {suggested_workers} or less")
    
    # Filter handicap n·∫øu c·∫ßn
    if filter_handicap:
        original_count = len(positions)
        positions = [p for p in positions if p.get('handicap', 0) == 0]
        filtered_count = len(positions)
        if filtered_count < original_count:
            logger.info(
                f"   Filtered out {original_count - filtered_count:,} "
                f"handicap positions"
            )
    
    # Auto-enable incremental save n·∫øu estimated memory > 4GB
    estimated_memory_mb = len(positions) * 50 / 1024
    auto_save_chunk_size = None
    if estimated_memory_mb > 4000:  # > 4GB
        # Auto-enable: save m·ªói 50K samples (~1.2GB)
        auto_save_chunk_size = 50000
        logger.info(
            f"üí° Auto-enabling incremental save (chunk size: {auto_save_chunk_size:,}) "
            f"to prevent MemoryError (estimated: ~{estimated_memory_mb:.0f}MB)"
        )
    
    # Setup output directory cho chunks
    output_path_obj = Path(output_path)
    output_dir = output_path_obj.parent
    chunks_dir = output_dir / f'{output_path_obj.stem}_chunks'
    
    # Generate labels v·ªõi multiprocessing
    result, errors = process_positions_to_labels_parallel(
        positions,
        board_size,
        num_workers=num_workers,
        batch_size=batch_size,
        save_chunk_size=auto_save_chunk_size,
        output_dir=chunks_dir if auto_save_chunk_size else None
    )
    
    # N·∫øu d√πng incremental save, result l√† list of chunk files
    if auto_save_chunk_size and isinstance(result, list):
        saved_chunks = result
        logger.info(f"üì¶ Merging {len(saved_chunks)} chunks...")
        
        # Merge chunks
        all_labeled_data = []
        for chunk_file in tqdm(saved_chunks, desc="Loading chunks"):
            chunk_data = torch.load(chunk_file, map_location='cpu', weights_only=False)
            all_labeled_data.extend(chunk_data['labeled_data'])
            # Cleanup chunk file sau khi load (optional - c√≥ th·ªÉ gi·ªØ ƒë·ªÉ backup)
            # chunk_file.unlink()
        
        logger.info(f"‚úÖ Merged {len(all_labeled_data):,} samples from {len(saved_chunks)} chunks")
        
        # Cleanup chunks directory (optional)
        # import shutil
        # shutil.rmtree(chunks_dir)
    else:
        all_labeled_data = result
    
    labeled_data = all_labeled_data
    
    # Log errors
    if errors:
        error_log_file = Path(output_path).parent / f'label_errors_{year or "all"}.log'
        with open(error_log_file, 'w', encoding='utf-8') as f:
            f.write(f"Label Generation Errors Summary\n")
            f.write(f"Total errors: {len(errors)}\n")
            f.write(f"Date: {datetime.now()}\n\n")
            
            # Group errors by type
            errors_by_type = {}
            for err in errors:
                err_type = err.get('type', 'unknown')
                if err_type not in errors_by_type:
                    errors_by_type[err_type] = []
                errors_by_type[err_type].append(err)
            
            f.write("Errors by type:\n")
            for err_type, err_list in errors_by_type.items():
                f.write(f"  {err_type}: {len(err_list)}\n")
            
            f.write("\nSample errors (first 100):\n")
            for err in errors[:100]:
                f.write(f"\nType: {err.get('type', 'unknown')}\n")
                f.write(f"Error: {err.get('error', 'N/A')}\n")
                if 'position' in err:
                    f.write(f"Position: {err['position']}\n")
        
        logger.warning(
            f"WARNING: {len(errors)} positions had errors. "
            f"See {error_log_file}"
        )
    
    # Save labeled dataset
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    torch.save({
        'labeled_data': labeled_data,
        'board_size': board_size,
        'total': len(labeled_data),
        'year': year,
        'metadata': {
            'filtered_handicap': filter_handicap,
            'input_file': str(input_path),
            'errors': len(errors),
            'date_processed': datetime.now().isoformat()
        }
    }, output_path)
    
    logger.info(
        f"SUCCESS: Saved {len(labeled_data):,} labeled samples to {output_path}"
    )
    
    # Summary
    total_processed = len(labeled_data) + len(errors)
    success_rate = (len(labeled_data) / total_processed * 100) if total_processed > 0 else 0
    
    logger.info("\n" + "="*50)
    logger.info("Label Generation Summary:")
    logger.info(f"  Input positions: {len(positions):,}")
    logger.info(f"  Processed positions: {total_processed:,}")
    logger.info(f"  Labeled samples: {len(labeled_data):,}")
    logger.info(f"  Errors: {len(errors):,}")
    logger.info(f"  Success rate: {success_rate:.2f}%")
    if len(errors) > 0:
        logger.info(f"  Error rate: {len(errors) / total_processed * 100:.2f}%")
    logger.info("="*50)
    
    return labeled_data


if __name__ == "__main__":
    import argparse
    
    # Signal handler ƒë·ªÉ cleanup khi Ctrl+C
    def signal_handler(sig, frame):
        logger.warning("\n‚ö†Ô∏è  Received interrupt signal. Cleaning up...")
        sys.exit(1)
    
    # Register signal handler cho SIGINT (Ctrl+C) v√† SIGTERM
    signal.signal(signal.SIGINT, signal_handler)
    if hasattr(signal, 'SIGTERM'):
        signal.signal(signal.SIGTERM, signal_handler)
    
    parser = argparse.ArgumentParser(description='Generate labels locally')
    parser.add_argument('--input', type=str, required=True,
                        help='Input positions file (.pt)')
    parser.add_argument('--output', type=str, required=True,
                        help='Output labeled dataset file (.pt)')
    parser.add_argument('--filter-handicap', action='store_true', default=True,
                        help='Filter out handicap positions')
    parser.add_argument('--no-filter-handicap', dest='filter_handicap',
                        action='store_false',
                        help='Keep handicap positions')
    parser.add_argument('--workers', type=int, default=None,
                        help='Number of worker processes (default: auto, max 8). '
                             'Gi·∫£m n·∫øu RAM b·ªã chi·∫øm nhi·ªÅu (v√≠ d·ª•: --workers 8)')
    parser.add_argument('--batch-size', type=int, default=5000,
                        help='Batch size for processing (default: 5000, t·ªëi ∆∞u cho performance). '
                             'Gi·∫£m n·∫øu RAM b·ªã chi·∫øm nhi·ªÅu (v√≠ d·ª•: --batch-size 2000)')
    
    args = parser.parse_args()
    
    # Auto-adjust workers n·∫øu kh√¥ng ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
    if args.workers is None:
        # Load file ƒë·ªÉ estimate s·ªë positions
        try:
            data = torch.load(args.input, map_location='cpu', weights_only=False)
            num_positions = len(data.get('positions', []))
            
            # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh: nhi·ªÅu positions -> √≠t workers h∆°n ƒë·ªÉ tr√°nh RAM overflow
            if num_positions > 1_000_000:  # > 1M positions
                suggested_workers = min(6, cpu_count())
            elif num_positions > 500_000:  # > 500K positions
                suggested_workers = min(8, cpu_count())
            else:
                suggested_workers = min(8, cpu_count())
            
            logger.info(
                f"Auto-detected {num_positions:,} positions. "
                f"Using {suggested_workers} workers (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh b·∫±ng --workers)"
            )
            args.workers = suggested_workers
        except Exception as e:
            logger.warning(f"Could not auto-detect positions count: {e}. Using default workers.")
            args.workers = min(8, cpu_count())
    
    # Validate workers
    if args.workers > 16:
        logger.warning(
            f"‚ö†Ô∏è  WARNING: {args.workers} workers c√≥ th·ªÉ g√¢y RAM overflow. "
            f"Khuy·∫øn ngh·ªã: --workers 8 ho·∫∑c √≠t h∆°n."
        )
    
    try:
        process_dataset_file(
            input_path=args.input,
            output_path=args.output,
            filter_handicap=args.filter_handicap,
            num_workers=args.workers,
            batch_size=args.batch_size
        )
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  Script interrupted by user. Exiting...")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Error: {e}")
        traceback.print_exc()
        sys.exit(1)

