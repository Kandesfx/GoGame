# ğŸš€ Tá»‘i Æ¯u Cho Colab Vá»›i 50GB RAM

## âœ… ÄÃ£ Tá»‘i Æ¯u Cho 50GB RAM

### 1. **Chunk Size Lá»›n HÆ¡n**
- âœ… Default: 100K samples (~5GB) thay vÃ¬ 15-20K
- âœ… Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh lÃªn Ä‘áº¿n 300K samples (~15GB)
- âœ… Giáº£m I/O overhead, táº­n dá»¥ng RAM

### 2. **Multiprocessing Enabled**
- âœ… Default: Enable multiprocessing
- âœ… Workers: 2-6 (tÃ¹y CPU cores)
- âœ… CÃ³ thá»ƒ xá»­ lÃ½ dataset lÃªn Ä‘áº¿n 1M positions

### 3. **Memory Management**
- âœ… Chunk size lá»›n hÆ¡n = Ã­t I/O hÆ¡n
- âœ… GC Ã­t thÆ°á»ng xuyÃªn hÆ¡n (má»—i 20K thay vÃ¬ 5K)
- âœ… Táº­n dá»¥ng RAM Ä‘á»ƒ cache nhiá»u data hÆ¡n

## ğŸ“‹ CÃ¡ch Sá»­ Dá»¥ng (50GB RAM)

### Recommended (Multiprocessing)

```python
from pathlib import Path
from generate_labels_colab import process_dataset_file

WORK_DIR = Path('/content/drive/MyDrive/GoGame_ML')

# Tá»‘i Æ°u cho 50GB RAM - multiprocessing enabled
process_dataset_file(
    input_path=WORK_DIR / 'processed' / 'positions_19x19_2019.pt',
    output_path=WORK_DIR / 'datasets' / 'labeled_19x19_2019.pt',
    filter_handicap=True
    # use_multiprocessing=True (default)
    # save_chunk_size tá»± Ä‘á»™ng = 100K-300K
    # num_workers tá»± Ä‘á»™ng = 2-6
)
```

### Manual Tuning

```python
# Tá»‘i Æ°u tá»‘i Ä‘a vá»›i 50GB RAM
process_dataset_file(
    input_path=...,
    output_path=...,
    save_chunk_size=200000,  # 200K samples (~10GB)
    use_multiprocessing=True,
    num_workers=6  # Max workers
)
```

### Single-Threaded (Náº¿u Multiprocessing GÃ¢y Váº¥n Äá»)

```python
# Fallback náº¿u multiprocessing váº«n gÃ¢y Ä‘á»©ng
process_dataset_file(
    ...,
    use_multiprocessing=False,
    save_chunk_size=150000  # Váº«n lá»›n hÆ¡n vá»›i 50GB RAM
)
```

## ğŸ“Š Performance (50GB RAM)

### Multiprocessing (Recommended):
- **Speed**: ~3000-5000 pos/s (vá»›i 4-6 workers)
- **Memory**: 10-20GB (táº­n dá»¥ng RAM)
- **Dataset**: LÃªn Ä‘áº¿n 1M positions

### Single-Threaded:
- **Speed**: ~100-150 pos/s
- **Memory**: 5-10GB
- **Stability**: âœ… Ráº¥t á»•n Ä‘á»‹nh

## âš™ï¸ Tuning Cho 50GB RAM

### Dataset Nhá» (<200K positions):
```python
save_chunk_size=300000  # 300K samples (~15GB) - táº­n dá»¥ng RAM tá»‘i Ä‘a
num_workers=6
```

### Dataset Trung BÃ¬nh (200K-500K positions):
```python
save_chunk_size=200000  # 200K samples (~10GB)
num_workers=4-6
```

### Dataset Lá»›n (>500K positions):
```python
save_chunk_size=100000  # 100K samples (~5GB)
num_workers=4  # Giáº£m workers Ä‘á»ƒ trÃ¡nh overhead
```

## ğŸ¯ Best Practices

1. **Táº­n dá»¥ng RAM**: DÃ¹ng chunk size lá»›n (100K-300K)
2. **Multiprocessing**: Enable vá»›i 4-6 workers
3. **Monitor**: Váº«n nÃªn monitor memory (dÃ¹ cÃ³ 50GB)
4. **I/O**: Chunk size lá»›n = Ã­t I/O hÆ¡n = nhanh hÆ¡n

## ğŸ“ˆ Expected Performance

Vá»›i dataset 624K positions trÃªn 50GB RAM:
- **Multiprocessing (6 workers)**: ~20-30 phÃºt (3000-5000 pos/s)
- **Single-threaded**: ~1.5-2 giá» (100-150 pos/s)
- **Speedup**: 3-5x vá»›i multiprocessing

## âš ï¸ LÆ°u Ã

1. **Multiprocessing**: Váº«n cÃ³ thá»ƒ gÃ¢y Ä‘á»©ng náº¿u khÃ´ng Ä‘Æ°á»£c implement Ä‘Ãºng
2. **Chunk Size**: DÃ¹ cÃ³ 50GB RAM, khÃ´ng nÃªn quÃ¡ 300K (trÃ¡nh overhead)
3. **Workers**: Max 6 workers (trÃ¡nh context switching overhead)

## ğŸ”— LiÃªn Quan

- `scripts/generate_labels_colab.py` - Script Ä‘Ã£ tá»‘i Æ°u
- `scripts/COLAB_PRO_OPTIMIZATION.md` - TÃ i liá»‡u multiprocessing
- `scripts/SINGLE_THREADED_OPTIMIZATION.md` - Fallback option

