# ğŸš€ HÆ¯á»šNG DáºªN TRAINING TRÃŠN COLAB

## ğŸ“‹ Tá»•ng Quan

CÃ¡c script nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y trÃªn Google Colab vá»›i GPU miá»…n phÃ­.

## ğŸ“ Cáº¥u TrÃºc Scripts

```
scripts/
â”œâ”€â”€ parse_sgf_colab.py              # Parse SGF files â†’ positions
â”œâ”€â”€ generate_features_colab.py      # Generate 17-plane features
â”œâ”€â”€ generate_labels_colab.py        # Generate policy + value labels
â”œâ”€â”€ train_colab.py                  # Training script hoÃ n chá»‰nh
â””â”€â”€ colab_notebook_template.py      # Template notebook vá»›i táº¥t cáº£ cells
```

## ğŸ¯ Workflow

### BÆ°á»›c 1: Parse SGF Files

```python
from parse_sgf_colab import process_sgf_directory
from pathlib import Path

WORK_DIR = Path('/content/drive/MyDrive/GoGame_ML')

process_sgf_directory(
    sgf_dir=WORK_DIR / 'raw_sgf',
    output_dir=WORK_DIR / 'processed',
    board_sizes=[9, 13, 19]
)
```

**Output:** `processed/positions_9x9.pt`, `processed/positions_13x13.pt`, ...

### BÆ°á»›c 2: Generate Labels

```python
from generate_labels_colab import process_dataset_file

process_dataset_file(
    input_path=WORK_DIR / 'processed' / 'positions_9x9.pt',
    output_path=WORK_DIR / 'datasets' / 'labeled_9x9.pt',
    filter_handicap=True
)
```

**Output:** `datasets/labeled_9x9.pt` vá»›i:
- `features`: Tensor [17, 9, 9]
- `policy`: Tensor [81]
- `value`: float

### BÆ°á»›c 3: Training

#### Training cÆ¡ báº£n (cho GPU nhá» hoáº·c test nhanh):
```python
from train_colab import train_model

train_model(
    train_dataset_path=str(WORK_DIR / 'datasets' / 'labeled_9x9.pt'),
    val_dataset_path=None,  # Auto-split
    board_size=9,
    batch_size=32,
    num_epochs=10,
    learning_rate=0.001,
    checkpoint_dir=str(WORK_DIR / 'checkpoints')
)
```

#### Training tá»‘i Æ°u GPU RAM (cho L4 24GB hoáº·c GPU lá»›n):
```python
from train_colab import train_model

train_model(
    train_dataset_path=str(WORK_DIR / 'datasets' / 'labeled_19x19.pt'),
    val_dataset_path=None,
    board_size=19,
    batch_size=4096,  # TÄƒng tá»« 1024 Ä‘á»ƒ táº­n dá»¥ng GPU RAM
    num_epochs=10,
    learning_rate=0.001,
    checkpoint_dir=str(WORK_DIR / 'checkpoints'),
    use_chunks=True,  # DÃ¹ng chunks Ä‘á»ƒ load dataset lá»›n
    model_channels=256,  # TÄƒng tá»« 128 Ä‘á»ƒ model lá»›n hÆ¡n
    max_train_samples=None,  # None = dÃ¹ng táº¥t cáº£ samples
    gradient_accumulation_steps=1,  # CÃ³ thá»ƒ tÄƒng Ä‘á»ƒ effective batch size lá»›n hÆ¡n
    enable_pin_memory=True,  # TÄƒng tá»‘c data loading
    checkpoint_prefix=None  # Auto-detect tá»« dataset path, hoáº·c set thá»§ cÃ´ng nhÆ° "dataset_2019"
)
```

**âš ï¸ Quan trá»ng - TrÃ¡nh ghi Ä‘Ã¨ checkpoint:**
- Khi train nhiá»u dataset khÃ¡c nhau, script sáº½ tá»± Ä‘á»™ng táº¡o prefix tá»« tÃªn dataset
- VÃ­ dá»¥: train tá»« `/content/split19` â†’ prefix = `split19`
- Checkpoint sáº½ Ä‘Æ°á»£c lÆ°u: `split19_checkpoint_epoch_1.pt`, `split19_best_model.pt`, etc.
- Náº¿u muá»‘n set thá»§ cÃ´ng: `checkpoint_prefix="dataset_2019"`

**Tá»‘i Æ°u GPU RAM:**
- **Batch size**: TÄƒng tá»« 1024 â†’ 4096 hoáº·c 8192 (tÃ¹y GPU RAM)
- **Model channels**: TÄƒng tá»« 128 â†’ 256 hoáº·c 512 (model lá»›n hÆ¡n, tá»‘t hÆ¡n)
- **Training samples**: Bá» giá»›i háº¡n 200k, dÃ¹ng táº¥t cáº£ 600k samples
- **Gradient accumulation**: Náº¿u muá»‘n effective batch size = 8192, dÃ¹ng batch_size=4096 + accumulation_steps=2

**Output:** 
- `checkpoints/best_model.pt` - Model tá»‘t nháº¥t
- `checkpoints/final_model.pt` - Model cuá»‘i cÃ¹ng
- `checkpoints/checkpoint_epoch_X.pt` - Checkpoints Ä‘á»‹nh ká»³

## ğŸ“ Sá»­ Dá»¥ng Template Notebook

1. Má»Ÿ `scripts/colab_notebook_template.py`
2. Copy tá»«ng cell vÃ o Colab notebook
3. Cháº¡y theo thá»© tá»± tá»« Cell 1 â†’ Cell 14

## ğŸ”§ Requirements

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install numpy pandas tqdm sgf
```

## ğŸ“Š Dataset Format

### Input (tá»« parse_sgf_colab.py):

```python
{
    'positions': [
        {
            'board_state': np.ndarray,  # [board_size, board_size]
            'move': (x, y),
            'current_player': 'B' or 'W',
            'winner': 'B' or 'W' or None,
            'game_result': 'B+12.5',
            ...
        },
        ...
    ],
    'board_size': 9,
    'total': 80000
}
```

### Output (tá»« generate_labels_colab.py):

```python
{
    'labeled_data': [
        {
            'features': torch.Tensor,  # [17, board_size, board_size]
            'policy': torch.Tensor,    # [board_size * board_size]
            'value': float,            # 0.0 - 1.0
            'metadata': {...}
        },
        ...
    ],
    'board_size': 9,
    'total': 80000
}
```

## ğŸ“ Model Output

Sau khi training, báº¡n sáº½ cÃ³:

1. **best_model.pt**: Model vá»›i validation loss tháº¥p nháº¥t
   ```python
   {
       'policy_net_state_dict': {...},
       'value_net_state_dict': {...},
       'policy_config': {...},
       'value_config': {...},
       'board_size': 9,
       'val_policy_loss': 0.5234,
       'val_value_loss': 0.1234
   }
   ```

2. **final_model.pt**: Model sau epoch cuá»‘i cÃ¹ng

3. **checkpoint_epoch_X.pt**: Checkpoints Ä‘á»ƒ resume training

## ğŸ”„ Loading Model for Inference (Sá»­ dá»¥ng trong App)

Sau khi training xong, báº¡n cáº§n load model Ä‘á»ƒ sá»­ dá»¥ng trong app. DÆ°á»›i Ä‘Ã¢y lÃ  hÆ°á»›ng dáº«n chi tiáº¿t:

### CÃ¡ch 1: Load tá»« `best_model.pt` (Khuyáº¿n nghá»‹)

```python
import torch
from policy_network import PolicyNetwork, PolicyConfig
from value_network import ValueNetwork, ValueConfig

# ÄÆ°á»ng dáº«n Ä‘áº¿n checkpoint
checkpoint_path = 'checkpoints/best_model.pt'  # hoáº·c 'final_model.pt'

# Load checkpoint
checkpoint = torch.load(checkpoint_path, map_location='cpu')

# Khá»Ÿi táº¡o model vá»›i config tá»« checkpoint
policy_config = PolicyConfig(**checkpoint['policy_config'])
value_config = ValueConfig(**checkpoint['value_config'])

policy_net = PolicyNetwork(policy_config)
value_net = ValueNetwork(value_config)

# Load weights vÃ o model
policy_net.load_state_dict(checkpoint['policy_net_state_dict'])
value_net.load_state_dict(checkpoint['value_net_state_dict'])

# Set model sang eval mode (quan trá»ng cho inference)
policy_net.eval()
value_net.eval()

# BÃ¢y giá» cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ predict
# VÃ­ dá»¥: predict move tá»« board state
with torch.no_grad():
    # features: Tensor [1, 17, board_size, board_size]
    policy_logits = policy_net(features)
    value_pred = value_net(features)
```

### CÃ¡ch 2: Load tá»« `final_model.pt`

```python
# TÆ°Æ¡ng tá»± nhÆ° trÃªn, chá»‰ Ä‘á»•i Ä‘Æ°á»ng dáº«n
checkpoint_path = 'checkpoints/final_model.pt'
checkpoint = torch.load(checkpoint_path, map_location='cpu')
# ... (pháº§n cÃ²n láº¡i giá»‘ng CÃ¡ch 1)
```

### CÃ¡ch 3: Load tá»« checkpoint epoch cá»¥ thá»ƒ

```python
# Load tá»« checkpoint epoch 3
checkpoint_path = 'checkpoints/checkpoint_epoch_3.pt'
checkpoint = torch.load(checkpoint_path, map_location='cpu')
# ... (pháº§n cÃ²n láº¡i giá»‘ng CÃ¡ch 1)
```

### LÆ°u Ã½ quan trá»ng:

1. **NÃªn dÃ¹ng `best_model.pt`**: Model nÃ y cÃ³ validation loss tháº¥p nháº¥t, thÆ°á»ng lÃ  model tá»‘t nháº¥t
2. **LuÃ´n set `eval()` mode**: Quan trá»ng Ä‘á»ƒ táº¯t dropout vÃ  batch normalization trong inference
3. **DÃ¹ng `torch.no_grad()`**: Táº¯t gradient computation Ä‘á»ƒ tiáº¿t kiá»‡m memory vÃ  tÄƒng tá»‘c
4. **`map_location='cpu'`**: Náº¿u load trÃªn CPU, hoáº·c `'cuda:0'` náº¿u load trÃªn GPU

### VÃ­ dá»¥ Ä‘áº§y Ä‘á»§: Load vÃ  sá»­ dá»¥ng trong app

```python
import torch
from policy_network import PolicyNetwork, PolicyConfig
from value_network import ValueNetwork, ValueConfig

class GoAIModel:
    def __init__(self, checkpoint_path='checkpoints/best_model.pt'):
        # Load checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # Khá»Ÿi táº¡o models
        policy_config = PolicyConfig(**checkpoint['policy_config'])
        value_config = ValueConfig(**checkpoint['value_config'])
        
        self.policy_net = PolicyNetwork(policy_config)
        self.value_net = ValueNetwork(value_config)
        
        # Load weights
        self.policy_net.load_state_dict(checkpoint['policy_net_state_dict'])
        self.value_net.load_state_dict(checkpoint['value_net_state_dict'])
        
        # Set eval mode
        self.policy_net.eval()
        self.value_net.eval()
        
        self.board_size = checkpoint['board_size']
    
    def predict_move(self, features):
        """
        Predict move tá»« board features.
        
        Args:
            features: Tensor [1, 17, board_size, board_size]
        
        Returns:
            policy: Tensor [board_size * board_size] - xÃ¡c suáº¥t cho má»—i move
            value: float - giÃ¡ trá»‹ vá»‹ trÃ­ (0-1)
        """
        with torch.no_grad():
            policy_logits = self.policy_net(features)
            value_pred = self.value_net(features)
        
        # Convert logits to probabilities
        policy_probs = torch.softmax(policy_logits, dim=1)
        
        return policy_probs[0], value_pred.item()

# Sá»­ dá»¥ng
model = GoAIModel('checkpoints/best_model.pt')
# ... dÃ¹ng model.predict_move(features) trong app
```

## ğŸ’¡ Tips

### Tá»‘i Æ°u GPU RAM (L4 24GB):
1. **Batch size**: TÄƒng lÃªn 4096-8192 Ä‘á»ƒ táº­n dá»¥ng GPU RAM
2. **Model channels**: TÄƒng tá»« 128 â†’ 256 hoáº·c 512
3. **Training samples**: Bá» giá»›i háº¡n, dÃ¹ng táº¥t cáº£ samples cÃ³ sáºµn
4. **Gradient accumulation**: DÃ¹ng Ä‘á»ƒ tÄƒng effective batch size mÃ  khÃ´ng cáº§n tÄƒng batch_size
5. **Pin memory**: Báº­t `enable_pin_memory=True` Ä‘á»ƒ tÄƒng tá»‘c data loading

### GPU Memory nhá»:
1. **GPU Memory**: Náº¿u háº¿t memory, giáº£m `batch_size` (4096 â†’ 2048 â†’ 1024 â†’ 512)
2. **Model channels**: Giáº£m tá»« 256 â†’ 128 â†’ 64 náº¿u cáº§n
3. **Training samples**: Giá»›i háº¡n sá»‘ samples vá»›i `max_train_samples`

### KhÃ¡c:
1. **Training Time**: 10 epochs cho 200K samples â‰ˆ 1-2 giá» trÃªn Colab L4 vá»›i batch_size=4096
2. **Save Checkpoints**: LÆ°u thÆ°á»ng xuyÃªn Ä‘á»ƒ trÃ¡nh máº¥t dá»¯ liá»‡u khi session timeout
3. **Data Augmentation**: ÄÃ£ Ä‘Æ°á»£c tÃ­ch há»£p trong `GoDataset` class
4. **Monitor GPU**: Script sáº½ tá»± Ä‘á»™ng in GPU RAM usage trong quÃ¡ trÃ¬nh training

## ğŸ› Troubleshooting

### Lá»—i: "CUDA out of memory"
- Giáº£m `batch_size` (4096 â†’ 2048 â†’ 1024)
- Giáº£m `model_channels` (256 â†’ 128 â†’ 64)
- Giáº£m `max_train_samples` náº¿u Ä‘ang dÃ¹ng quÃ¡ nhiá»u
- TÄƒng `gradient_accumulation_steps` vÃ  giáº£m `batch_size` Ä‘á»ƒ giá»¯ effective batch size

### GPU RAM chÆ°a Ä‘Æ°á»£c táº­n dá»¥ng tá»‘i Ä‘a
- TÄƒng `batch_size` lÃªn 4096 hoáº·c 8192
- TÄƒng `model_channels` lÃªn 256 hoáº·c 512
- Bá» `max_train_samples` Ä‘á»ƒ dÃ¹ng táº¥t cáº£ data
- Kiá»ƒm tra GPU memory usage trong log Ä‘á»ƒ xem cÃ²n bao nhiÃªu RAM trá»‘ng

### Lá»—i: "Module not found"
- Upload code files vÃ o Drive
- Hoáº·c copy code trá»±c tiáº¿p vÃ o cells

### Lá»—i: "File not found"
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n
- Äáº£m báº£o Ä‘Ã£ mount Drive

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- Chi tiáº¿t: `docs/ML_TRAINING_COLAB_GUIDE.md`
- Kaggle guide: `docs/ML_TRAINING_KAGGLE_GUIDE.md`
- Comprehensive guide: `docs/ML_COMPREHENSIVE_GUIDE.md`

